<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Piece One">
  <!-- Open Graph Data -->
  <meta property="og:title" content="notes/Spark部署模式与作业提交"/>
  <meta property="og:description" content="爱吃鱼的Blog" />
  <meta property="og:site_name" content="TLUYZ&#39;Blog"/>
  <meta property="og:type" content="article" />
  <meta property="og:image" content="http://yoursite.com"/>
  
    <link rel="alternate" href="/atom.xml" title="TLUYZ&#39;Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  

  <!-- Site Title -->
  <title>TLUYZ'Blog</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/css/style.light.css">

  <!-- Google Analytics -->
  

</head>

  <body>
    <!-- Page Header -->


<header class="site-header header-background" style="background-image: url(/img/default-banner-dark.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">notes/Spark部署模式与作业提交</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/xiaobaigitb" target="_blank" rel="noopener">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="mailto:<your-email-address>">
                  
                  Email
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
            <!-- Author -->
            <span class="author info">By Piece One</span>
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2019-12-02</span>
            <span class="time">22:05:46</span>
          </span>
          
        </div>
        <!-- Tags -->
        
        <!-- Post Main Content -->
        <div class="post-content">
          <h1 id="Spark部署模式与作业提交"><a href="#Spark部署模式与作业提交" class="headerlink" title="Spark部署模式与作业提交"></a>Spark部署模式与作业提交</h1><nav>
<a href="#一作业提交">一、作业提交</a><br/>
<a href="#二Local模式">二、Local模式</a><br/>
<a href="#三Standalone模式">三、Standalone模式</a><br/>
<a href="#三Spark-on-Yarn模式">三、Spark on Yarn模式</a><br/>
</nav>


<h2 id="一、作业提交"><a href="#一、作业提交" class="headerlink" title="一、作业提交"></a>一、作业提交</h2><h3 id="1-1-spark-submit"><a href="#1-1-spark-submit" class="headerlink" title="1.1  spark-submit"></a>1.1  spark-submit</h3><p>Spark 所有模式均使用 <code>spark-submit</code> 命令提交作业，其格式如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">  --class &lt;main-class&gt; \        # 应用程序主入口类</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">  --master &lt;master-url&gt; \       # 集群的 Master Url</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">  --deploy-mode &lt;deploy-mode&gt; \ # 部署模式</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">  --conf &lt;key&gt;=&lt;value&gt; \        # 可选配置       </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">  ... # other options    </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">  &lt;application-jar&gt; \           # Jar 包路径 </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">  [application-arguments]       #传递给主入口类的参数</span></pre></td></tr></table></figure>

<p>需要注意的是：在集群环境下，<code>application-jar</code> 必须能被集群中所有节点都能访问，可以是 HDFS 上的路径；也可以是本地文件系统路径，如果是本地文件系统路径，则要求集群中每一个机器节点上的相同路径都存在该 Jar 包。</p>
<h3 id="1-2-deploy-mode"><a href="#1-2-deploy-mode" class="headerlink" title="1.2 deploy-mode"></a>1.2 deploy-mode</h3><p>deploy-mode 有 <code>cluster</code> 和 <code>client</code> 两个可选参数，默认为 <code>client</code>。这里以 Spark On Yarn 模式对两者进行说明 ：</p>
<ul>
<li>在 cluster 模式下，Spark Drvier 在应用程序的 Master 进程内运行，该进程由群集上的 YARN 管理，提交作业的客户端可以在启动应用程序后关闭；</li>
<li>在 client 模式下，Spark Drvier 在提交作业的客户端进程中运行，Master 进程仅用于从 YARN 请求资源。</li>
</ul>
<h3 id="1-3-master-url"><a href="#1-3-master-url" class="headerlink" title="1.3 master-url"></a>1.3 master-url</h3><p>master-url 的所有可选参数如下表所示：</p>
<table>
<thead>
<tr>
<th>Master URL</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><code>local</code></td>
<td>使用一个线程本地运行 Spark</td>
</tr>
<tr>
<td><code>local[K]</code></td>
<td>使用 K 个 worker 线程本地运行 Spark</td>
</tr>
<tr>
<td><code>local[K,F]</code></td>
<td>使用 K 个 worker 线程本地运行 , 第二个参数为 Task 的失败重试次数</td>
</tr>
<tr>
<td><code>local[*]</code></td>
<td>使用与 CPU 核心数一样的线程数在本地运行 Spark</td>
</tr>
<tr>
<td><code>local[*,F]</code></td>
<td>使用与 CPU 核心数一样的线程数在本地运行 Spark<br/>第二个参数为 Task 的失败重试次数</td>
</tr>
<tr>
<td><code>spark://HOST:PORT</code></td>
<td>连接至指定的 standalone 集群的 master 节点。端口号默认是 7077。</td>
</tr>
<tr>
<td><code>spark://HOST1:PORT1,HOST2:PORT2</code></td>
<td>如果 standalone 集群采用 Zookeeper 实现高可用，则必须包含由 zookeeper 设置的所有 master 主机地址。</td>
</tr>
<tr>
<td><code>mesos://HOST:PORT</code></td>
<td>连接至给定的 Mesos 集群。端口默认是 5050。对于使用了 ZooKeeper 的 Mesos cluster 来说，使用 <code>mesos://zk://...</code> 来指定地址，使用 <code>--deploy-mode cluster</code> 模式来提交。</td>
</tr>
<tr>
<td><code>yarn</code></td>
<td>连接至一个 YARN 集群，集群由配置的 <code>HADOOP_CONF_DIR</code> 或者 <code>YARN_CONF_DIR</code> 来决定。使用 <code>--deploy-mode</code> 参数来配置 <code>client</code> 或 <code>cluster</code> 模式。</td>
</tr>
</tbody></table>
<p>下面主要介绍三种常用部署模式及对应的作业提交方式。</p>
<h2 id="二、Local模式"><a href="#二、Local模式" class="headerlink" title="二、Local模式"></a>二、Local模式</h2><p>Local 模式下提交作业最为简单，不需要进行任何配置，提交命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 本地模式提交应用</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">spark-submit \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">--class org.apache.spark.examples.SparkPi \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">--master local[2] \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">/usr/app/spark-2.4.0-bin-hadoop2.6/examples/jars/spark-examples_2.11-2.4.0.jar \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">100   # 传给 SparkPi 的参数</span></pre></td></tr></table></figure>

<p><code>spark-examples_2.11-2.4.0.jar</code> 是 Spark 提供的测试用例包，<code>SparkPi</code> 用于计算 Pi 值，执行结果如下：</p>
<div align="center"> <img src="https://github.com/heibaiying/BigData-Notes/blob/master/pictures/spark-pi.png"/> </div>



<h2 id="三、Standalone模式"><a href="#三、Standalone模式" class="headerlink" title="三、Standalone模式"></a>三、Standalone模式</h2><p>Standalone 是 Spark 提供的一种内置的集群模式，采用内置的资源管理器进行管理。下面按照如图所示演示 1 个 Mater 和 2 个 Worker 节点的集群配置，这里使用两台主机进行演示：</p>
<ul>
<li>hadoop001： 由于只有两台主机，所以 hadoop001 既是 Master 节点，也是 Worker 节点;</li>
<li>hadoop002 ： Worker 节点。</li>
</ul>
<div align="center"> <img src="https://github.com/heibaiying/BigData-Notes/blob/master/pictures/spark-集群模式.png"/> </div>

<h3 id="3-1-环境配置"><a href="#3-1-环境配置" class="headerlink" title="3.1 环境配置"></a>3.1 环境配置</h3><p>首先需要保证 Spark 已经解压在两台主机的相同路径上。然后进入 hadoop001 的 <code>${SPARK_HOME}/conf/</code> 目录下，拷贝配置样本并进行相关配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cp spark-env.sh.template spark-env.sh</span></span></pre></td></tr></table></figure>

<p>在 <code>spark-env.sh</code> 中配置 JDK 的目录，完成后将该配置使用 scp 命令分发到 hadoop002 上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> JDK安装位置</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/usr/java/jdk1.8.0_201</span></pre></td></tr></table></figure>

<h3 id="3-2-集群配置"><a href="#3-2-集群配置" class="headerlink" title="3.2 集群配置"></a>3.2 集群配置</h3><p>在 <code>${SPARK_HOME}/conf/</code> 目录下，拷贝集群配置样本并进行相关配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"># cp slaves.template slaves</span></pre></td></tr></table></figure>

<p>指定所有 Worker 节点的主机名：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> A Spark Worker will be started on each of the machines listed below.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">hadoop001</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">hadoop002</span></pre></td></tr></table></figure>

<p>这里需要注意以下三点：</p>
<ul>
<li>主机名与 IP 地址的映射必须在 <code>/etc/hosts</code> 文件中已经配置，否则就直接使用 IP 地址；</li>
<li>每个主机名必须独占一行；</li>
<li>Spark 的 Master 主机是通过 SSH 访问所有的 Worker 节点，所以需要预先配置免密登录。</li>
</ul>
<h3 id="3-3-启动"><a href="#3-3-启动" class="headerlink" title="3.3 启动"></a>3.3 启动</h3><p>使用 <code>start-all.sh</code> 代表启动 Master 和所有 Worker 服务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">./sbin/start-master.sh</span></pre></td></tr></table></figure>

<p>访问 8080 端口，查看 Spark 的 Web-UI 界面,，此时应该显示有两个有效的工作节点：</p>
<div align="center"> <img src="https://github.com/heibaiying/BigData-Notes/blob/master/pictures/spark-Standalone-web-ui.png"/> </div>

<h3 id="3-4-提交作业"><a href="#3-4-提交作业" class="headerlink" title="3.4 提交作业"></a>3.4 提交作业</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 以client模式提交到standalone集群 </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">spark-submit \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">--class org.apache.spark.examples.SparkPi \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">--master spark://hadoop001:7077 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">--executor-memory 2G \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">--total-executor-cores 10 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">/usr/app/spark-2.4.0-bin-hadoop2.6/examples/jars/spark-examples_2.11-2.4.0.jar \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">100</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 以cluster模式提交到standalone集群 </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">spark-submit \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">--class org.apache.spark.examples.SparkPi \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">--master spark://207.184.161.138:7077 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">--deploy-mode cluster \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">--supervise \  # 配置此参数代表开启监督，如果主应用程序异常退出，则自动重启 Driver</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">--executor-memory 2G \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">--total-executor-cores 10 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">/usr/app/spark-2.4.0-bin-hadoop2.6/examples/jars/spark-examples_2.11-2.4.0.jar \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">100</span></pre></td></tr></table></figure>

<h3 id="3-5-可选配置"><a href="#3-5-可选配置" class="headerlink" title="3.5 可选配置"></a>3.5 可选配置</h3><p>在虚拟机上提交作业时经常出现一个的问题是作业无法申请到足够的资源：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="attr">Initial</span> <span class="string">job has not accepted any resources; </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="attr">check</span> <span class="string">your cluster UI to ensure that workers are registered and have sufficient resources</span></span></pre></td></tr></table></figure>

<div align="center"> <img src="https://github.com/heibaiying/BigData-Notes/blob/master/pictures/spark-内存不足2.png"/> </div>

<br/>

<p>这时候可以查看 Web UI，我这里是内存空间不足：提交命令中要求作业的 <code>executor-memory</code> 是 2G，但是实际的工作节点的 <code>Memory</code> 只有 1G，这时候你可以修改 <code>--executor-memory</code>，也可以修改 Woker 的 <code>Memory</code>，其默认值为主机所有可用内存值减去 1G。</p>
<div align="center"> <img src="https://github.com/heibaiying/BigData-Notes/blob/master/pictures/spark-内存不足.png"/> </div>   

<br/>

<p>关于 Master 和 Woker 节点的所有可选配置如下，可以在 <code>spark-env.sh</code> 中进行对应的配置：    </p>
<table>
<thead>
<tr>
<th>Environment Variable（环境变量）</th>
<th>Meaning（含义）</th>
</tr>
</thead>
<tbody><tr>
<td><code>SPARK_MASTER_HOST</code></td>
<td>master 节点地址</td>
</tr>
<tr>
<td><code>SPARK_MASTER_PORT</code></td>
<td>master 节点地址端口（默认：7077）</td>
</tr>
<tr>
<td><code>SPARK_MASTER_WEBUI_PORT</code></td>
<td>master 的 web UI 的端口（默认：8080）</td>
</tr>
<tr>
<td><code>SPARK_MASTER_OPTS</code></td>
<td>仅用于 master 的配置属性，格式是 “-Dx=y”（默认：none）,所有属性可以参考官方文档：<a href="https://spark.apache.org/docs/latest/spark-standalone.html#spark-standalone-mode" target="_blank" rel="noopener">spark-standalone-mode</a></td>
</tr>
<tr>
<td><code>SPARK_LOCAL_DIRS</code></td>
<td>spark 的临时存储的目录，用于暂存 map 的输出和持久化存储 RDDs。多个目录用逗号分隔</td>
</tr>
<tr>
<td><code>SPARK_WORKER_CORES</code></td>
<td>spark worker 节点可以使用 CPU Cores 的数量。（默认：全部可用）</td>
</tr>
<tr>
<td><code>SPARK_WORKER_MEMORY</code></td>
<td>spark worker 节点可以使用的内存数量（默认：全部的内存减去 1GB）；</td>
</tr>
<tr>
<td><code>SPARK_WORKER_PORT</code></td>
<td>spark worker 节点的端口（默认： random（随机））</td>
</tr>
<tr>
<td><code>SPARK_WORKER_WEBUI_PORT</code></td>
<td>worker 的 web UI 的 Port（端口）（默认：8081）</td>
</tr>
<tr>
<td><code>SPARK_WORKER_DIR</code></td>
<td>worker 运行应用程序的目录，这个目录中包含日志和暂存空间（default：SPARK_HOME/work）</td>
</tr>
<tr>
<td><code>SPARK_WORKER_OPTS</code></td>
<td>仅用于 worker 的配置属性，格式是 “-Dx=y”（默认：none）。所有属性可以参考官方文档：<a href="https://spark.apache.org/docs/latest/spark-standalone.html#spark-standalone-mode" target="_blank" rel="noopener">spark-standalone-mode</a></td>
</tr>
<tr>
<td><code>SPARK_DAEMON_MEMORY</code></td>
<td>分配给 spark master 和 worker 守护进程的内存。（默认： 1G）</td>
</tr>
<tr>
<td><code>SPARK_DAEMON_JAVA_OPTS</code></td>
<td>spark master 和 worker 守护进程的 JVM 选项，格式是 “-Dx=y”（默认：none）</td>
</tr>
<tr>
<td><code>SPARK_PUBLIC_DNS</code></td>
<td>spark master 和 worker 的公开 DNS 名称。（默认：none）</td>
</tr>
</tbody></table>
<h2 id="三、Spark-on-Yarn模式"><a href="#三、Spark-on-Yarn模式" class="headerlink" title="三、Spark on Yarn模式"></a>三、Spark on Yarn模式</h2><p>Spark 支持将作业提交到 Yarn 上运行，此时不需要启动 Master 节点，也不需要启动 Worker 节点。</p>
<h3 id="3-1-配置"><a href="#3-1-配置" class="headerlink" title="3.1 配置"></a>3.1 配置</h3><p>在 <code>spark-env.sh</code> 中配置 hadoop 的配置目录的位置，可以使用 <code>YARN_CONF_DIR</code> 或 <code>HADOOP_CONF_DIR</code> 进行指定：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="attr">YARN_CONF_DIR</span>=<span class="string">/usr/app/hadoop-2.6.0-cdh5.15.2/etc/hadoop</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># JDK安装位置</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="attr">JAVA_HOME</span>=<span class="string">/usr/java/jdk1.8.0_201</span></span></pre></td></tr></table></figure>

<h3 id="3-2-启动"><a href="#3-2-启动" class="headerlink" title="3.2 启动"></a>3.2 启动</h3><p>必须要保证 Hadoop 已经启动，这里包括 YARN 和 HDFS 都需要启动，因为在计算过程中 Spark 会使用 HDFS 存储临时文件，如果 HDFS 没有启动，则会抛出异常。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> start-yarn.sh</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> start-dfs.sh</span></span></pre></td></tr></table></figure>

<h3 id="3-3-提交应用"><a href="#3-3-提交应用" class="headerlink" title="3.3 提交应用"></a>3.3 提交应用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">  以client模式提交到yarn集群 </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">spark-submit \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">--class org.apache.spark.examples.SparkPi \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">--master yarn \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">--deploy-mode client \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">--executor-memory 2G \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">--num-executors 10 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">/usr/app/spark-2.4.0-bin-hadoop2.6/examples/jars/spark-examples_2.11-2.4.0.jar \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">100</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">  以cluster模式提交到yarn集群 </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">spark-submit \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">--class org.apache.spark.examples.SparkPi \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">--master yarn \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">--deploy-mode cluster \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">--executor-memory 2G \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">--num-executors 10 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">/usr/app/spark-2.4.0-bin-hadoop2.6/examples/jars/spark-examples_2.11-2.4.0.jar \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">100</span></pre></td></tr></table></figure>




        </div>
      </div>
    </div>
  </div>
</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <p class="copyright text-muted">
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        <p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
        </p>
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  </body>
</html>

